"""
Progressive disclosure skill loader for ADR-034.

Provides three levels of skill loading to minimize token usage:
- Level 1: Metadata only (~100-200 tokens) - YAML frontmatter
- Level 2: Full SKILL.md content (~500-1000 tokens)
- Level 3: Resources on demand - files from references/ directory

Robustness features (ADR-034 v2.2):
- Path traversal protection (#292)
- Domain-specific exceptions (#293)
- Thread safety (#294)
- Cache invalidation (#295)
- Logging and observability (#296)
"""

from __future__ import annotations

import logging
import re
import threading
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional

import yaml

# Module logger
logger = logging.getLogger(__name__)

# Constants (#296)
SKILL_FILENAME = "SKILL.md"
REFERENCES_DIR = "references"
DEFAULT_SEARCH_PATHS = [".github/skills", ".claude/skills"]

# Valid skill name pattern: lowercase alphanumeric with hyphens, starting with letter/number
SKILL_NAME_PATTERN = re.compile(r"^[a-z0-9][a-z0-9-]*$")


class SkillError(Exception):
    """Base exception for skill loading errors."""

    pass


class SkillNotFoundError(SkillError):
    """Raised when a skill or resource is not found."""

    pass


class SkillParseError(SkillError):
    """Raised when skill content cannot be parsed."""

    pass


def _validate_skill_name(skill_name: str) -> None:
    """Validate skill name to prevent path traversal attacks.

    Args:
        skill_name: Name of skill to validate

    Raises:
        ValueError: If skill name is invalid or contains path traversal patterns
    """
    if not skill_name or not skill_name.strip():
        raise ValueError("Skill name cannot be empty")

    # Check for path traversal patterns
    if ".." in skill_name or "/" in skill_name or "\\" in skill_name:
        raise ValueError(f"Path traversal detected in skill name: {skill_name}")

    # Check against valid pattern
    if not SKILL_NAME_PATTERN.match(skill_name):
        raise ValueError(
            f"Invalid skill name '{skill_name}': must be lowercase alphanumeric with hyphens, "
            "starting with a letter or number"
        )


@dataclass
class SkillMetadata:
    """Level 1: Skill metadata from YAML frontmatter.

    Contains only essential information for skill discovery and selection.
    Target: ~100-200 tokens.
    """

    name: str
    description: str
    license: Optional[str] = None
    compatibility: Optional[str] = None
    allowed_tools: List[str] = field(default_factory=list)
    category: Optional[str] = None
    domain: Optional[str] = None
    author: Optional[str] = None
    repository: Optional[str] = None

    @property
    def estimated_tokens(self) -> int:
        """Estimate token count for this metadata.

        Uses rough approximation of ~4 characters per token.
        """
        text = f"{self.name} {self.description}"
        if self.license:
            text += f" {self.license}"
        if self.compatibility:
            text += f" {self.compatibility}"
        if self.allowed_tools:
            text += f" {' '.join(self.allowed_tools)}"
        if self.category:
            text += f" {self.category}"
        if self.domain:
            text += f" {self.domain}"

        return len(text) // 4


@dataclass
class SkillFull:
    """Level 2: Full skill content including body.

    Contains metadata plus the complete SKILL.md body.
    Target: ~500-1000 tokens.
    """

    metadata: SkillMetadata
    body: str

    @property
    def estimated_tokens(self) -> int:
        """Estimate token count for full content."""
        return self.metadata.estimated_tokens + len(self.body) // 4


# Regex to match YAML frontmatter
FRONTMATTER_PATTERN = re.compile(
    r"^---\s*\n(.*?)\n---\s*\n",
    re.DOTALL,
)


def _parse_frontmatter(content: str) -> tuple[Dict, str]:
    """Parse YAML frontmatter from skill content.

    Args:
        content: Full SKILL.md content

    Returns:
        Tuple of (frontmatter dict, body string)

    Raises:
        SkillParseError: If frontmatter is missing or invalid
    """
    match = FRONTMATTER_PATTERN.match(content)
    if not match:
        raise SkillParseError("SKILL.md must start with YAML frontmatter (--- delimiters)")

    try:
        frontmatter = yaml.safe_load(match.group(1))
        if not isinstance(frontmatter, dict):
            raise SkillParseError("YAML frontmatter must be a mapping")
    except yaml.YAMLError as e:
        raise SkillParseError(f"Invalid YAML in frontmatter: {e}")

    body = content[match.end() :].strip()
    return frontmatter, body


def _parse_allowed_tools(value: Optional[str]) -> List[str]:
    """Parse allowed-tools string into list.

    Args:
        value: Space-separated tool names or None

    Returns:
        List of tool names
    """
    if not value:
        return []
    return value.split()


def load_skill_metadata(content: str) -> SkillMetadata:
    """Load Level 1 metadata from skill content.

    Parses only the YAML frontmatter to extract essential metadata.
    This is the most token-efficient way to discover skill capabilities.

    Args:
        content: Full SKILL.md content string

    Returns:
        SkillMetadata with essential fields

    Raises:
        SkillParseError: If content is invalid
    """
    frontmatter, _ = _parse_frontmatter(content)

    # Required fields
    if "name" not in frontmatter:
        raise SkillParseError("SKILL.md frontmatter must include 'name' field")

    if "description" not in frontmatter:
        raise SkillParseError("SKILL.md frontmatter must include 'description' field")

    # Extract nested metadata
    nested_meta = frontmatter.get("metadata", {})

    return SkillMetadata(
        name=frontmatter["name"],
        description=frontmatter["description"],
        license=frontmatter.get("license"),
        compatibility=frontmatter.get("compatibility"),
        allowed_tools=_parse_allowed_tools(frontmatter.get("allowed-tools")),
        category=nested_meta.get("category"),
        domain=nested_meta.get("domain"),
        author=nested_meta.get("author"),
        repository=nested_meta.get("repository"),
    )


def load_skill_full(content: str) -> SkillFull:
    """Load Level 2 full skill content.

    Parses both frontmatter metadata and the complete body.
    Use when skill has been selected and full instructions are needed.

    Args:
        content: Full SKILL.md content string

    Returns:
        SkillFull with metadata and body

    Raises:
        SkillParseError: If content is invalid
    """
    frontmatter, body = _parse_frontmatter(content)
    metadata = load_skill_metadata(content)

    return SkillFull(
        metadata=metadata,
        body=body,
    )


def load_skill_resource(path: Path) -> str:
    """Load Level 3 resource file content.

    Loads additional reference files on demand.
    Use only when specific resource content is needed.

    Args:
        path: Path to resource file

    Returns:
        Resource file content

    Raises:
        SkillNotFoundError: If resource doesn't exist
    """
    if not path.exists():
        raise SkillNotFoundError(f"Resource not found: {path}")

    return path.read_text(encoding="utf-8")


class SkillLoader:
    """Progressive disclosure skill loader.

    Discovers and loads skills from a directory structure:
    ```
    skills_dir/
    ├── skill-name/
    │   ├── SKILL.md
    │   └── references/
    │       ├── rubrics.md
    │       └── examples.md
    ```

    Supports three loading levels:
    - Level 1: load_metadata() - Just YAML frontmatter
    - Level 2: load_full() - Complete SKILL.md
    - Level 3: load_resource() - Reference files

    Thread-safe with cache invalidation support (ADR-034 v2.2).
    """

    def __init__(self, skills_dir: Path):
        """Initialize loader with skills directory.

        Args:
            skills_dir: Path to directory containing skill subdirectories
        """
        self.skills_dir = skills_dir
        self._metadata_cache: Dict[str, SkillMetadata] = {}
        self._lock = threading.RLock()  # Thread safety (#294)

    def list_skills(self) -> List[str]:
        """List all available skill names.

        Returns:
            List of skill directory names that contain SKILL.md
        """
        if not self.skills_dir.exists():
            return []

        skills = []
        for item in self.skills_dir.iterdir():
            if item.is_dir() and (item / SKILL_FILENAME).exists():
                skills.append(item.name)

        return sorted(skills)

    def _get_skill_path(self, skill_name: str) -> Path:
        """Get path to skill directory.

        Args:
            skill_name: Name of skill

        Returns:
            Path to skill directory

        Raises:
            ValueError: If skill name is invalid (path traversal protection)
            SkillNotFoundError: If skill doesn't exist
        """
        # Validate skill name first (path traversal protection #292)
        _validate_skill_name(skill_name)

        skill_path = self.skills_dir / skill_name
        skill_md = skill_path / SKILL_FILENAME

        if not skill_md.exists():
            raise SkillNotFoundError(f"Skill not found: {skill_name}")

        return skill_path

    def load_metadata(self, skill_name: str) -> SkillMetadata:
        """Load Level 1 metadata for a skill.

        Caches results for performance. Thread-safe.

        Args:
            skill_name: Name of skill to load

        Returns:
            SkillMetadata with essential fields

        Raises:
            ValueError: If skill name is invalid
            SkillNotFoundError: If skill doesn't exist
            SkillParseError: If SKILL.md is invalid
        """
        logger.debug(f"Loading metadata for skill: {skill_name}")

        with self._lock:
            if skill_name in self._metadata_cache:
                logger.debug(f"Returning cached metadata for: {skill_name}")
                return self._metadata_cache[skill_name]

        skill_path = self._get_skill_path(skill_name)
        content = (skill_path / SKILL_FILENAME).read_text(encoding="utf-8")
        metadata = load_skill_metadata(content)

        with self._lock:
            self._metadata_cache[skill_name] = metadata

        logger.info(f"Successfully loaded skill metadata: {skill_name}")
        return metadata

    def load_full(self, skill_name: str) -> SkillFull:
        """Load Level 2 full content for a skill.

        Args:
            skill_name: Name of skill to load

        Returns:
            SkillFull with metadata and body

        Raises:
            ValueError: If skill name is invalid
            SkillNotFoundError: If skill doesn't exist
            SkillParseError: If SKILL.md is invalid
        """
        logger.debug(f"Loading full content for skill: {skill_name}")
        skill_path = self._get_skill_path(skill_name)
        content = (skill_path / SKILL_FILENAME).read_text(encoding="utf-8")
        return load_skill_full(content)

    def list_resources(self, skill_name: str) -> List[str]:
        """List available Level 3 resources for a skill.

        Args:
            skill_name: Name of skill

        Returns:
            List of resource filenames in references/ directory

        Raises:
            ValueError: If skill name is invalid
            SkillNotFoundError: If skill doesn't exist
        """
        skill_path = self._get_skill_path(skill_name)
        refs_dir = skill_path / REFERENCES_DIR

        if not refs_dir.exists():
            return []

        return sorted([f.name for f in refs_dir.iterdir() if f.is_file()])

    def load_resource(self, skill_name: str, resource_name: str) -> str:
        """Load Level 3 resource content.

        Args:
            skill_name: Name of skill
            resource_name: Filename in references/ directory

        Returns:
            Resource file content

        Raises:
            ValueError: If skill name is invalid
            SkillNotFoundError: If skill or resource doesn't exist
        """
        skill_path = self._get_skill_path(skill_name)
        resource_path = skill_path / REFERENCES_DIR / resource_name

        return load_skill_resource(resource_path)

    def invalidate_cache(self, skill_name: Optional[str] = None) -> None:
        """Invalidate cached skill data.

        Thread-safe cache invalidation for refreshing stale data.

        Args:
            skill_name: If provided, invalidate only this skill.
                        If None, clear all cached data.
        """
        with self._lock:
            if skill_name is not None:
                logger.debug(f"Invalidating cache for skill: {skill_name}")
                self._metadata_cache.pop(skill_name, None)
            else:
                logger.debug("Invalidating all cached skill data")
                self._metadata_cache.clear()
